{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6001f894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f22bbd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a381ffc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Outcome\"]).values\n",
    "y = df['Outcome'].values\n",
    "\n",
    "X_min = X.min(axis=0)\n",
    "X_max = X.max(axis=0) \n",
    "X = (X - X_min) / (X_max - X_min)\n",
    "\n",
    "X = np.hstack([np.ones((X.shape[0], 1)), X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d362d61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, train_ratio, val_ratio, test_ratio):\n",
    "    n = len(X)\n",
    "    idx = np.random.permutation(n)\n",
    "    X, y = X[idx], y[idx]\n",
    "    \n",
    "    train_size = int(train_ratio * n)\n",
    "    val_size = int(val_ratio * n)\n",
    "    \n",
    "    X_train, y_train = X[:train_size], y[:train_size]\n",
    "    X_val, y_val = X[train_size:train_size+val_size], y[train_size:train_size+val_size]\n",
    "    X_test, y_test = X[train_size+val_size:], y[train_size+val_size:]\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44a85dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def predict(X, theta):\n",
    "    return sigmoid(np.dot(X, theta))\n",
    "\n",
    "def cutoff(y_pred_probs):\n",
    "    return (y_pred_probs >= 0.5).astype(int)\n",
    "\n",
    "def accuracy(y_true, y_pred_probs):\n",
    "    y_pred = cutoff(y_pred_probs)\n",
    "    return np.mean(y_pred == y_true)\n",
    "\n",
    "def rss(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "def log_loss(y_true, y_pred_probs, eps=1e-15):\n",
    "    y_pred_probs = np.clip(y_pred_probs, eps, 1 - eps)\n",
    "    return -np.mean(y_true * np.log(y_pred_probs) + (1 - y_true) * np.log(1 - y_pred_probs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14c5ff43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_bgd(X, y, alpha=0.1, rho=1e-6, max_epochs=1000):\n",
    "    m, n = X.shape\n",
    "    theta = np.zeros(n)\n",
    "    prev_loss = float(\"inf\")\n",
    "    loss_history = []\n",
    "\n",
    "    for _ in range(max_epochs):\n",
    "        y_pred = predict(X, theta)             \n",
    "        grad = (1/m) * X.T.dot(y_pred - y)    \n",
    "        theta -= alpha * grad                 \n",
    "\n",
    "        loss = log_loss(y, y_pred)           \n",
    "        loss_history.append(loss)\n",
    "\n",
    "        if abs(prev_loss - loss) < rho:\n",
    "            break\n",
    "        prev_loss = loss\n",
    "\n",
    "    return theta, loss_history\n",
    "\n",
    "\n",
    "def logistic_regression_sgd(X, y, alpha=0.01, rho=1e-6, max_epochs=1000):\n",
    "    m, n = X.shape\n",
    "    theta = np.zeros(n)\n",
    "    prev_loss = float(\"inf\")\n",
    "    loss_history = []\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        idx = np.random.permutation(m)\n",
    "        X_shuffled, y_shuffled = X[idx], y[idx]\n",
    "\n",
    "        for i in range(m):\n",
    "            xi = X_shuffled[i].reshape(1, -1)\n",
    "            yi = y_shuffled[i]\n",
    "            y_pred_i = predict(xi, theta)    \n",
    "            grad_i = xi.T * (y_pred_i - yi)\n",
    "            theta -= alpha * grad_i.flatten()\n",
    "\n",
    "        y_pred_all = predict(X, theta)     \n",
    "        loss = log_loss(y, y_pred_all)\n",
    "        loss_history.append(loss)\n",
    "\n",
    "        if abs(prev_loss - loss) < rho:\n",
    "            break\n",
    "        prev_loss = loss\n",
    "\n",
    "    return theta, loss_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f18c160f",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [(0.5, 0.1, 0.4), (0.6, 0.1, 0.3), (0.7,0.1,0.2), (0.8, 0.1, 0.1)]\n",
    "alphas = [0.01, 0.1]\n",
    "rhos = [1e-6, 1e-5]\n",
    "epochs_list = [500, 1000]\n",
    "\n",
    "import os\n",
    "os.makedirs(\"plots\", exist_ok=True)\n",
    "os.makedirs(\"results\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2b46857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y, method=\"bgd\"):\n",
    "    results = []\n",
    "    output_results = []\n",
    "    best_params_final = None\n",
    "    overall_best_val_rss = float(\"inf\")\n",
    "\n",
    "    for split in splits:\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test = split_data(X, y, *split)\n",
    "        best_val_rss = float(\"inf\")\n",
    "        best_theta = None\n",
    "        best_history = None\n",
    "        best_params = None\n",
    "\n",
    "        for alpha in alphas:\n",
    "            for rho in rhos:\n",
    "                for max_epoch in epochs_list:\n",
    "                    if method == \"bgd\":\n",
    "                        theta, history = logistic_regression_bgd(X_train, y_train, alpha, rho, max_epoch)\n",
    "                    else:\n",
    "                        theta, history = logistic_regression_sgd(X_train, y_train, alpha, rho, max_epoch)\n",
    "\n",
    "                    y_val_pred = predict(X_val, theta)\n",
    "                    val_rss = rss(y_val, y_val_pred)\n",
    "\n",
    "                    if val_rss < best_val_rss:\n",
    "                        best_val_rss = val_rss\n",
    "                        best_theta = theta\n",
    "                        best_history = history\n",
    "                        best_params = (alpha, rho, max_epoch)\n",
    "\n",
    "        if best_val_rss < overall_best_val_rss:\n",
    "            overall_best_val_rss = best_val_rss\n",
    "            best_params_final = best_params\n",
    "\n",
    "\n",
    "        y_train_pred = predict(X_train, best_theta)\n",
    "        y_test_pred = predict(X_test, best_theta)\n",
    "        train_acc = accuracy(y_train, y_train_pred)\n",
    "        test_acc = accuracy(y_test, y_test_pred)\n",
    "\n",
    "        results.append([split, best_params, train_acc, test_acc])\n",
    "\n",
    "        output_results.append([split, cutoff(y_train_pred).tolist(), y_train.tolist(), \n",
    "                               cutoff(y_test_pred).tolist(),y_test.tolist()\n",
    "                            ])\n",
    "        \n",
    "        split_str = f\"{split[0]}_{split[1]}_{split[2]}\"\n",
    "        plt.plot(best_history)\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Log Loss\")\n",
    "        plt.title(f\"{method.upper()} Training Curve Split={split}\")\n",
    "        plt.savefig(f\"plots/{method}_training_curve_{split_str}.png\")\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    df_results = pd.DataFrame(results, columns=[\"Split\", \"Best Params (alpha,rho,epochs)\", \"Train Accuracy\", \"Test Accuracy\"])\n",
    "    df_results.to_csv(f\"results/{method}_final_results.csv\", index=False)\n",
    "\n",
    "    df_outputs = pd.DataFrame(output_results, columns=[\"Split\", \"y_train_pred\", \"y_train\", \"y_test_pred\", \"y_test\"])\n",
    "    df_outputs.to_csv(f\"results/{method}_train_test_predictions.csv\", index=False)\n",
    "\n",
    "    print(f\"{method.upper()} training complete!\")\n",
    "    print(\"Overall best hyperparameters:\", best_params_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63c04009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BGD training complete!\n",
      "Overall best hyperparameters: (0.1, 1e-06, 1000)\n",
      "SGD training complete!\n",
      "Overall best hyperparameters: (0.01, 1e-05, 1000)\n"
     ]
    }
   ],
   "source": [
    "train_model(X, y, method=\"bgd\")\n",
    "train_model(X, y, method=\"sgd\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
